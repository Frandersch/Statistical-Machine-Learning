% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[german]{babel}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{csquotes}
\AtBeginDocument{
\renewcommand{\maketitle}{}
}
\PassOptionsToPackage{a4paper,margin = 2.5cm}{geometry}
\usepackage{geometry}
\newcommand{\bcenter}{\begin{center}}
\newcommand{\ecenter}{\end{center}}
\renewcommand{\contentsname}{Inhalt}
\usepackage{blindtext}
\usepackage[backend=biber, style = apa]{biblatex}
\addbibresource{Literatur.bib}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{Literatur.bib}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Pros und Cons},
  pdfauthor={Franz Andersch \& Niklas Münz},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Pros und Cons}
\author{Franz Andersch \& Niklas Münz}
\date{2024-08-27}

\begin{document}
\maketitle

Support Vector Machines haben ein hohes Ansehen unter den Machine
Learning Algorithmen, da sie einige Vorteile mit sich bringen. Aufgrund
der Idee einer Soft Margin und des ``Kernel Tricks'' ist die Methode
sehr flexibel und kann für spezielle Anwendungsbereiche angepasst werden
\parencite{bennettSupportVectorMachines2000}.Dazu sind die Ergebnisse
stabil und reproduzierbar, was sie von anderen Methoden wie
beispielsweise Neural Networks abhebt. Auch die Anwendung ist
vergleichsweise einfach, da es eine überschaubare Anzahl an Parametern
gibt (wie beispielsweise bei der \textit{SVM} mit radialem Kern nur der
gamma- und cost-Parameter festzulegen ist).\newline Durch die
Möglichkeit der Nutzung verschiedener Kerne sind \textit{SVM} überaus
vielseitig. Die Auswahl des Kerns ermöglicht es äußerst flexible
Entscheidungsgrenzen zu formen
\parencite{kuhnAppliedPredictiveModeling2013}. Dadurch können
\textit{SVM} an verschiedene Datensituationen angepasst werden.\newline
Ein weiterer Vorteil ist, dass die Methode weitgehend robust gegenüber
overfitting ist \parencite{kuhnAppliedPredictiveModeling2013}. Dafür
verantwortlich ist der Cost-Parameter, anhand dessen der Fit an die
Daten kontrolliert werden kann. Jedoch birgt dies auch Probleme
(Erläuterungen im folgenden Abschnitt).\newline Diese Vorteile
resultieren in einer allgemein häufigen Nutzung von \textit{SVM} in der
Wissenschaft. Sie haben folglich bewiesen, dass sie für verschiedenste
Aufgaben gut funktionieren
\parencite{kuhnAppliedPredictiveModeling2013}.

Trotz der vielfachen Nutzung von \textit{SVM}, bringen sie auch
Nachteile mit sich. Das wohl größte Problem liegt in der Modellselektion
\parencite{bennettSupportVectorMachines2000}. Wie bereits im vorherigen
Abschnitt erwähnt, ist die Auswahl der Parameter von hoher Bedeutung bei
der Performance und dem Fit an die Daten. So kontrollieren die
Kernspezifischen Parameter und der Cost-Parameter einerseits die
Komplexität und andererseits den Fit an die Daten
\parencite{kuhnAppliedPredictiveModeling2013}. Dabei kann die Wahl der
Parameter sowohl zu einem underfit als auch zu einem overfit führen.
Jedoch haben nicht nur die Parameter einen Einfluss auf die Performance
sondern bereits die Wahl des Kerns kann entscheidend sein
\parencite{burgesTutorialSupportVector1998}. Je nach Datensituation
können \textit{SVM} mit verschiedenen Kernen äußerst unterschiedliche
Ergebnisse liefern. Dies zeigt die Sensitivität der Methode gegenüber
der Wahl des Kerns und der Parameterabstimmung.\newline Ein weiterer
Nachteil ist, dass die Methode weniger intuitiv und aufwendiger
anzuwenden ist als andere Algorithmen
\parencite{bennettSupportVectorMachines2000}. So ist es zum Beispiel
schwer Informationen aus Support Vektoren zu ziehen und es gibt keine
Koeffizienten die interpretiert werden können.\newline Zuletzt ist zu
erwähnen, dass die Methode bei einer hohen Anzahl an Beobachtungen
besonders rechenintensiv ist. So konnte beispielsweise gezeigt werden,
dass insbesondere die \textit{SVM} mit polynomialem und radialem Kern
eine hohe Rechenzeit aufweisen
\parencite{scholzComparisonClassificationMethods2021}. Dabei konnten
andere Methoden wie die \textit{logistische Regression} oder
\textit{k-nearest Neighbour} deutlich besser abschneiden. Dies liegt
daran, dass die Lösung des \textit{SVM}-Optimierungsproblems die
Behebung eines quadratischen Programmierungsproblems erfordert. Da die
Anzahl der zu optimierenden Parameter mit der Anzahl der Daten
quadratisch zunimmt, führt dies zu einer hohen Rechenkomplexität
\parencite{kecmanSupportVectorMachines2005}.

\printbibliography

\end{document}
