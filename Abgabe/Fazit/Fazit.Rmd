---
title: "Fazit"
author: "Franz Andersch & Niklas Münz"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    number_sections: true
    keep_tex: true
    includes:
      in_header: header.tex
    citation_package: biblatex
bibliography: Literatur.bib
---

In unserer Arbeit haben wir zum einen die Funktionsweise der \textit{Support Vector Machines} als binäre Klassifikationsmethode beleuchtet, als auch die Leistungsfähigkeit in Datenszenarien mit verschiedenen Eigenschaften verglichen. Diese Datensszenarien, wurden synthetisch von uns hergestellt und sind in ihrem datengenerierenden Prozess speziell auf \textit{SVM} zugeschnitten. Anschließend haben wir uns mit einschlägiger Literatur beschäftigt, bei der die Autoren bereits ähnliche Versuche durchgeführt haben und anhand dessen Hypothesen abgeleitet. Für die Durchführung unserer Versuche haben wir die Performance von \textit{SVM} mit verschiedenen Kernels sowie weiterer Klassifikationsmethoden über alle Szenarien mit verschiedenen Maßzahlen verglichen. \newline 
Insgesamt mussten wir allerdings festellen, dass unsere Ergebnisse die Hypothesen nur in Teilen bestätigen. \textit{SVM}-Methoden, haben im Durschnitt oft bessere Leistungen gezeigt, als die anderen Methoden. Wir schließen aufgrund der Rankings, dass, egal welche Dimensionierung vorliegt und wenn keine Information über die Form der Entscheidungsgrenze vorliegt, \textit{SVM} mit radialen und polynomialen Kernel immer eine gute Entscheidung darstellen. Zumindest sollten diese beiden dem \textit{SVM} mit linearem Kernel vorgezogen werden. Wobei hier auch anzumerken ist, dass mit der höheren Flexibilität der \textit{SVM-P} und \textit{SVM-R} auch die Gefahr besteht, dass es zu Overfitting kommt. Dies könnte vor allem bei empirischen Daten zu höheren Klassifikationsfehlern führen.\newline
Allerdings haben wider Erwarten die \textit{SVM} mit dem Kernel der auf die Datenerzeugung eigentlich zugeschnitten ist nicht besser performt. 
Wir vermuten, dass es an einem zu niedrigen $n$-Wert in der Dimensionierung für die Szenarien 4 bis 9 liegen könnte und dass sich in einer etwaigen Simulationsstudie mit dem gleichen DGP und Dimensionierung die Hypothese vielleicht doch noch bestätigen könnte, da sich so zufällige Abweichungen aufheben. 
Was das Verhalten in den verschiedenen Dimensionalitäten angeht können wir zumindest sagen, dass in Fällen mit mehr Beobachtungen als Variablen \textit{SVM} eine gute Wahl darstellen. Schwieriger wird es bei den hochdimensionalen Szenarien, da hier \textit{K-NN} eindeutig besser performt hat. Uns fällt es schwer dies zu erklären, da wir eigentlich davon ausgingen, dass \textit{K-NN} bei vielen Variablen eher schlechter performt.

Wir sehen daher Optimierungsmöglichkeiten für weitere Arbeiten dieser Art. So wäre es angebracht, wie bereits erwähnt die Datengererierung für die einzelnen Szenarien wiederholt durchzuführen und die Ergebnisse zu mitteln. Die Dimesnionierung könnte auch so angepasst werden, dass die $n$ Werte etwas höher sind auch für Szenarien mit $p \gg n$.  
Des Weiteren könnte der Einfluss der Szenarien auf die Berechnungszeit für die \textit{SVM}-Algorithmen noch einbezogen werden. Ein Benchmark-Test könnte auch hier zu interessanten Ergebnissen führen. Zusätzlich haben wir hier lediglich eine handvoll Klassifikationsalgorithmen im Vergleich untersucht. Eine Erweiterung auf \textit{Classification Trees}, \textit{Discriminant Analysis} oder verschiedene \textit{Ensemble-Methoden} ist denkbar. An der Datengenerierung ließen sich ebenfalls weitere Aspekte anpassen. So könnte die Anteile der Ausprägungen in der binären Zielvariable noch variiert, mehr als zwei Ausprägungen generiert oder auch komplexere Entscheidungsgrenzen modelliert werden. Diese Erweiterungen hätten allerdings den Rahmen dieser Arbeit überschritten.
Trotzdem ergänzt unsere Arbeit die bisherigen Befunde zur Leistungs- und Anpassungsfähigkeit von \textit{Support-Vector Machines} in verschiedenen Datensituation, sowie deren Bedeutung im Kontext von Klassifikationsaufgaben.
