% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[german]{babel}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{csquotes}
\AtBeginDocument{
\renewcommand{\maketitle}{}
}
\PassOptionsToPackage{a4paper,margin = 2.5cm}{geometry}
\usepackage{geometry}
\usepackage{float}
\usepackage{enumitem}
\newcommand{\bcenter}{\begin{center}}
\newcommand{\ecenter}{\end{center}}
\renewcommand{\contentsname}{Inhalt}
\usepackage{blindtext}
\usepackage[backend=biber, style = apa]{biblatex}
\addbibresource{Literatur.bib}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{Literatur.bib}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Hypothesen},
  pdfauthor={Franz Andersch \& Niklas Münz},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Hypothesen}
\author{Franz Andersch \& Niklas Münz}
\date{2024-08-27}

\begin{document}
\maketitle

Im Folgenden werden Studien hinzugezogen, um eine Einschätzung der
Performance in den verschiedenen Szenarien vorzunehmen und Hypothesen
abzuleiten. Vorab ist zu erwähnen, dass die Evaluation von
Klassifikationsmethoden anhand synthetischer Datensätze in der Literatur
begrenzt ist. Da für diese Arbeit die Form der Entscheidungsgrenze
entscheidend ist, werden dennoch auschließlich Arbeiten mit
synthetischen Datensätzen zu Rate gezogen.\newline Aufgrund dessen, dass
der Datengenerierende Prozess hier so ausgearbeitet wurde, dass er mit
den Annahmen der \textit{SVM} arbeitet, erwarten wir zuerst einmal eine
bessere Performance der \textit{SVM} Classifier im Vergleich zu den
anderen Methoden.

\begin{minipage}{0.9\linewidth}
\begin{itemize}[leftmargin=0.1\linewidth]
\item[\textbf{H1:}] Die \textit{SVM}-Classifier Performen über alle Datensituationen im Durchschnitt besser als die anderen Classifier
\end{itemize}
\end{minipage}

Des Weiteren wurden in den einzelnen Kategorien des Daten generierenden
Prozesses die Entscheidungsgrenzen speziell auf verschiedene Kernels der
\textit{SVM} zugeschnitten. Daher sollten \textit{SVM} mit linearem
Kernel im Setting mit linearer Entscheidungsgrenze mindestens so gut
oder besser als die restlichen Classifier performen. Gleiches gilt für
\textit{SVM} mit polynomialen Kernel im Setting mit einer quadratischen
Entscheidungsgrenze und radiale Kernel bei einer Hypershäre als
Entscheidungsgrenze.

\begin{minipage}{0.9\linewidth}
\begin{itemize}[leftmargin=0.1\linewidth]
\item[\textbf{H2:}] Die \textit{SVM}-Classifier mit dem Kernel, der für den jeweiligen DGP zugeschnitten ist sollten mindestens genauso gut oder besser performen als die restlichen Classifier
\end{itemize}
\end{minipage}

Es konnte weiterhin gezeigt werden, dass in einem Szenario, indem
erheblich mehr Beobachtungen als Dimensionen und eine lineare
Entscheidungsgrenze vorliegen (S1), deutliche Unterschiede zwischen
\textit{SVM}, \textit{K-NN} und \textit{logistischer Regression} bei der
Diskriminationsfähigkeit auftreten
\parencite{entezari-malekiComparisonClassificationMethods2009}.
\textit{K-NN} und \textit{SVM} mit linearem Kernel zeigen AUC-Werte nahe
1 auf, was für eine nahezu perfekte Differenzierung der Klassen spricht.
Die \textit{logistische Regression} hingegen hat einen Wert knapp über
0.5, was nur etwas besser als eine Zufallsauswahl ist. Darüber hinaus
ist festzustellen, dass die Unterschiede deutlicher werden, je höher die
Anzahl an Beobachtungen ist.\newline Für den Fall einer radialen
Entscheidungsgrenze (S3) sind die Ergebnisse ähnlich. So erreicht in
diesem Beispiel eine \textit{SVM} mit radialem Kernel im Vergleich zu
einer logistischen Regression eine um 34\% höhere Genauigkeit
\parencite{faveroClassificationPerformanceEvaluation2022}. Basierend auf
den Ergebnissen der genannten Studien können folgende Schlussfolgerungen
gezogen werden.

\begin{minipage}{0.9\linewidth}
\begin{itemize}[leftmargin=0.1\linewidth]
\item[\textbf{H3:}] In niedrigdimensionalen Szenarien performen \textit{K-NN} und \textit{SVM} besser als eine \textit{logistische Regression}.
\end{itemize}
\end{minipage}

Die Szenarien S4 bis S6 finden in der Literatur kaum Beachtung, weshalb
hier keine Studien herangezogen werden können. Liegt jedoch ein Szenario
vor, indem die Anzahl der Dimensionen erheblich größer ist, als die
Anzahl der Beobachtungen, mit einer linearen Entscheidungsgrenze (S7),
sind die Ergebnisse differenzierter zu betrachten. So schneidet die
\textit{SVM} mit polynomialem Kernel am besten unter den genannten
Algorithmen ab, jedoch die \textit{SVM} mit linearem Kernel am
schlechtesten (als Kriterium wurde die mittlere Performance über 100
Datensätze evaluiert)
\parencite{scholzComparisonClassificationMethods2021}. Während
\textit{K-NN} auch in diesem Szenario eine gute Performance hat,
schneiden \textit{logistische Regression} und \textit{SVM} mit radialem
Kern mittelmäßig ab. Hierbei ist wichtig zu erwähnen, dass in der Studie
keine Ergebnisse über die genaue Performance präsentiert wurden, sondern
lediglich die Ränge der 25 behandelten Klassifikationsmethoden. Somit
können nur eingeschränkte Schlussfolgerungen gezogen werden.

In hochdimensionalen Szenarien zeigt vermutlich die \textit{SVM} mit
polynomialem oder radialem Kern eine gute Performance, unabhängig von
der Form der Entscheidungsgrenze, während die linearen \textit{SVM}
voraussichtlich weniger gut abschneiden wird. Es scheint so, dass auch
\textit{K-NN} und \textit{logistische Regression} in hochdimensionalen
Szenarien zumindest mittelmäßig abschneiden. Hier ist jedoch zu
beachten, dass nur eine lineare Entscheidungsgrenze betrachtet wurde und
in den Szenarien S8 und S9 andere Ergebnisse möglich sind. Es ist aber
auch bekannt, dass gerade die \textit{K-NN} Methode in hochdimensionalen
Settings schlechter performt
\parencite{jamesIntroductionStatisticalLearning2021}, während
\textit{SVM} für solche Fälle sehr oft Verwendung finden
\parencite{moguerzaSupportVectorMachines2006}. Wir schließen Final
daraus:

\begin{minipage}{0.9\linewidth}
\begin{itemize}[leftmargin=0.1\linewidth]
\item[\textbf{H4:}] In hochdimensionalen Settings performen v.a. \textit{SVM} mit radialen und polynomialen Kernel besser als die anderen Klassifikationsmethoden
\end{itemize}
\end{minipage}

\printbibliography

\end{document}
