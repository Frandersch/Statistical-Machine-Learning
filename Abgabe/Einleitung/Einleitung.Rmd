---
title: "Einleitung"
author: "Franz Andersch & Niklas Münz"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    number_sections: true
    keep_tex: true
    includes:
      in_header: header.tex
    citation_package: biblatex
bibliography: Literatur.bib
---
Warum eine gerade Ebene manchmal die beste Möglichkeit ist, um Daten in zwei klassen aufzuteilen? Darum soll es in dieser Arbeit gehen. Wir wollen hier die Methode der Support Vector Machines, die mit dieser Annahme arbeitet, erläutern und gleichzeitig auf den Prüfstand stellen. Denn auch wenn die Grundidee, vielleicht etwas zu simpel klingt, ist ihre Leistung was vor allem binäre Klassifikationprobleme angeht unumstritten. Die Grundlage für eine optimal seperierende Hyperebene wurde bereits 1964 von Alexej Chervonenkis und Vladimir Vapnik gelegt und die Methode wurde anschließend von mehrern Autoren stetig erweitert \parencite{vapnikEstimationDependencesBased2006}. 
Zuerst wollen wir die Funktionsweise der SVM näher beleuchten. Dazu wird zuerst gezeigt wie die Konstruktion dieser seperiernden Hypereben in dem Fall funktioniert, in dem die Daten tasächlich linear trennbar sind. Danach soll gezeigt werden wie eine Soft Margin Klassifier funktioniert, der auch funktioniert bei nicht perfekt linear trennbaren Daten und zuletzt soll es um die Anwendung von Kernels gehen, die es dann auch ermöglichen, nicht lineare Entscheidungsgrenzen herzustellen.
im Kapitel 3 wollen wir dann die Vor und Nachteile der Methode uns anschauen. Anhand dieser Informationen konnten wir uns dann bereits einige Gedanken zur Leistung der SVM in unserem Datenexperiment machen. Wie wir dieses Experiment aufbauen soll im nachfolgenden Kapitel beschrieben werden. Wir generieren uns zum anschließenden Vergleich neun verschiedene Datenszenarien, welche in ihrer Dimensionalitäten und Kompleixität der Entscheidungsgrenze variieren. Für den Vergleich wollen wir dann Klassifikationsleistung von SVM uns anderen Klassifikationsmethoden vegleichen. Im Teil Hypothesen haben wir aufgrund von Literatur, die bereits ähnliche Versuche durchgeführt haben, Vermutungen aufgestellt, wie die einzelnen Classifier im Vergleich abschneiden werden. 
Im Ergebnis-Teil wollen wir dann das Experiment durchführen und mithilfe von verschiedenen Maßzahlen die Leistung evaluieren. Ebenfalls wollen wir üperprüfen, ob die Hypothesen die wir zuvor aufgestellt haben sich bewahrheiten. 
Im letzen Teil soll ein Fazit gezogen werden, in dem Wir die Ergebnisse noch einmal diskutieren und Defitite in unserer Arbeit aufarbeiten.

