% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[german]{babel}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{csquotes}
\AtBeginDocument{
\renewcommand{\maketitle}{}
}
\PassOptionsToPackage{a4paper,margin = 2.5cm}{geometry}
\usepackage{geometry}
\newcommand{\bcenter}{\begin{center}}
\newcommand{\ecenter}{\end{center}}
\renewcommand{\contentsname}{Inhalt}
\usepackage{blindtext}
\usepackage[backend=biber, style = apa]{biblatex}
\addbibresource{Literatur.bib}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{Literatur.bib}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Einleitung},
  pdfauthor={Franz Andersch \& Niklas Münz},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Einleitung}
\author{Franz Andersch \& Niklas Münz}
\date{2024-08-30}

\begin{document}
\maketitle

Bei der Separierung von zwei Datenklassen scheint eine lineare
Trennlinie zwischen die Klassen zu ziehen eine simple und intuitive
Methode zu sein. Genau auf dieser Idee basieren
\textit{Support Vector Machines} (\textit{SVM}). Jedoch sind Daten nicht
immer perfekt trennbar oder es liegt keine lineare Trennlinie vor. Wie
\textit{SVM} funktionieren, wie sie mit solchen Situationen umgehen, wie
sie unter vorgegebenen Bedingungen performen und welche
Schlussfolgerungen für die praktische Anwendung gezogen werden können,
soll in dieser Arbeit beleuchtet werden.

Die Grundlage für eine optimal separierende Hyperebene wurde bereits
1964 von Alexej Chervonenkis und Vladimir Vapnik gelegt und die Methode
wurde anschließend von mehreren Autoren stetig erweitert
\parencite{vapnikEstimationDependencesBased2006}. Seitdem ist ihre
Leistung, trotz großer Fortschritte im Bereich neuronaler Netze, vor
allem was binärer Klassifikationsprobleme angeht unumstritten und sie
gelten dabei als eine der meistgenutzten Methoden
\parencite{soofiClassificationTechniquesMachine2017}. Dabei bieten
\textit{SVM} eine große Anzahl an Anwendungsmöglichkeiten, wie
beispielsweise, in der Bildklassifikation, in der Bioinformatik
(Krebsklassifikation) oder im Aufdecken von Kreditkartenbetrug
\parencite{cervantesComprehensiveSurveySupport2020}.

In dieser Arbeit wollen wir zuerst die Funktionsweise der \textit{SVM}
näher betrachten. Dazu wird zunächst gezeigt wie die Konstruktion dieser
separierenden Hypereben im Falle linear trennbarer Daten funktioniert.
Daraufhin wird die Idee eines Soft Margin Classifier aufgegriffen, der
sich dem Problem nicht trennbarer Daten annimmt. Zuletzt geht es um die
Anwendung von Kernels, die es ermöglichen, nicht lineare
Entscheidungsgrenzen herzustellen.\newline In Kapitel 3 werden dann die
Vor- und Nachteile der Methode betrachtet. Anhand dieser Informationen
werden Schlussfolgerungen zur Leistung der \textit{SVM} gezogen. Darauf
aufbauend wird im folgenden Kapitel der Aufbau unseres Experiments
beschrieben. Wir generieren uns zum anschließenden Vergleich neun
verschiedene Datenszenarien, welche in ihrer Dimensionalität und
Komplexität der Entscheidungsgrenze variieren. Für die Evaluierung der
Klassifikationsleistung werden neben den \textit{SVM} weitere
Klassifikationsmethoden herangezogen.\newline Im Kapitel Hypothesen
wurden auf Basis von Literatur, in der bereits ähnliche Versuche
durchgeführt wurden, Vermutungen aufgestellt, wie die einzelnen
Klassifikationsmethoden im Vergleich abschneiden werden.\newline Es
folgen die Ergebnisse, in denen die Durchführung des Experiments
beschrieben und die Leistungen anhand verschiedener Maßzahlen evaluiert
werden. Darüber hinaus wird überprüft, ob sich die Hypothesen, die wir
zuvor aufgestellt haben bewahrheitet haben. Im letzten Abschnitt wird
ein Fazit gezogen, indem die Ergebnisse diskutiert und mögliche Ansätze
zur Verbesserung unserer Arbeit vorgeschlagen werden.

\printbibliography

\end{document}
