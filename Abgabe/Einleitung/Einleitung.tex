% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[german]{babel}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{csquotes}
\AtBeginDocument{
\renewcommand{\maketitle}{}
}
\PassOptionsToPackage{a4paper,margin = 2.5cm}{geometry}
\usepackage{geometry}
\newcommand{\bcenter}{\begin{center}}
\newcommand{\ecenter}{\end{center}}
\renewcommand{\contentsname}{Inhalt}
\usepackage{blindtext}
\usepackage[backend=biber, style = apa]{biblatex}
\addbibresource{Literatur.bib}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{Literatur.bib}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Einleitung},
  pdfauthor={Franz Andersch \& Niklas Münz},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Einleitung}
\author{Franz Andersch \& Niklas Münz}
\date{2024-08-27}

\begin{document}
\maketitle

Bei der Separierung von zwei Datenklassen scheint eine lineare
Trennlinie zwischen die Klassen zu ziehen eine simple und intuitive
Methode zu sein. Genau auf dieser Idee basieren Support Vector Machines
(SVM). Jedoch sind Daten nicht immer perfekt trennbar oder es liegt
keine lineare Trennlinie vor. Wie SVM funktionieren, wie sie mit solchen
Situationen umgehen, wie sie unter vorgegebenen Bedingungen performen
und welche Schlussfolgerungen für die praktische Anwendung gezogen
werden können, soll in dieser Arbeit beleuchtet werden.

Die Grundlage für eine optimal separierende Hyperebene wurde bereits
1964 von Alexej Chervonenkis und Vladimir Vapnik gelegt und die Methode
wurde anschließend von mehreren Autoren stetig erweitert
\parencite{vapnikEstimationDependencesBased2006}. Seitdem ist ihre
Leistung, trotz großer Fortschritte im Bereich neuronaler Netze, vor
allem im Bereich binärer Klassifikationprobleme unumstritten und sie
gelten dabei als eine der meistgenutzten Methoden
\parencite{soofiClassificationTechniquesMachine2017}. Dabei bieten SVM
eine große Anzahl an Anwendungsmöglichkeiten, wie beipielsweise, in der
Bildklassifikation, in der Bioinformatik (Krebsklassifikation) oder im
Aufedecken von Kreditkartenbetrug
\parencite{cervantesComprehensiveSurveySupport2020}.

In dieser Arbeit wollen wir zuerst die Funktionsweise der SVM näher
betrachten. Dazu wird zunächst gezeigt wie die Konstruktion dieser
separierenden Hypereben im Falle linear trennbarer Daten funktioniert.
Daraufhin wird die Idee eines Soft Margin Klassifier aufgegriffen, der
sich dem Problem nicht trennbarer Daten annimmt. Zuletzt geht es um die
Anwendung von Kernels, die es ermöglichen, nichtlineare
Entscheidungsgrenzen herzustellen.\newline In Kapitel 3 werden dann die
Vor und Nachteile der Methode betrachtet. Anhand dieser Informationen
werden Schlussfolgerungen zur Leistung der SVM gezogen. Darauf aufbauend
wird im folgenden Kapitel der Aufbau unseres Experiments beschrieben.
Wir generieren uns zum anschließenden Vergleich neun verschiedene
Datenszenarien, welche in ihrer Dimensionalität und Kompleixität der
Entscheidungsgrenze variieren. Für die Evaluierung der
Klassifikationsleistung werden neben den SVM weitere
Klassifikationsmtehoden herangezogen.\newline Im Kapitel Hypothesen
wurden auf Basis von Literatur, in der bereits ähnliche Versuche
durchgeführt wurden, Vermutungen aufgestellt, wie die einzelnen
Klassifikationsmethoden im Vergleich abschneiden werden.\newline Es
folgen die Ergebnisse, in denen die Durchführung des Experiments
beschrieben und die Leistungen anhand verschiedener Maßzahlen evaluiert
werden. Darüber hinaus wird überprüft, ob sich die Hypothesen die wir
zuvor aufgestellt haben bewahrheitet haben. Im letzten Abschnitt wird
ein Fazit gezogen, indem die Ergebnisse noch einmal diskutiert und
Defizite in unserer Arbeit aufgearbeitet werden.

\printbibliography

\end{document}
